paddle.abs(x, name=None)
paddle.acos(x, name=None)
paddle.acosh(x, name=None)
paddle.add(x, y, name=None)
paddle.add_n(inputs, name=None)
paddle.addmm(input, x, y, beta=1.0, alpha=1.0, name=None)
paddle.all(x, axis=None, keepdim=False, name=None)
paddle.allclose(x, y, rtol=1e-05, atol=1e-08, equal_nan=False, name=None)
paddle.amax(x, axis=None, keepdim=False, name=None)
paddle.amin(x, axis=None, keepdim=False, name=None)
paddle.angle(x, name=None)
paddle.any(x, axis=None, keepdim=False, name=None)
paddle.arange(start=0, end=None, step=1, dtype=None, name=None)
paddle.argmax(x, axis=None, keepdim=False, dtype='int64', name=None)
paddle.argmin(x, axis=None, keepdim=False, dtype='int64', name=None)
paddle.argsort(x, axis=-1, descending=False, name=None)
paddle.as_complex(x, name=None)
paddle.as_real(x, name=None)
paddle.asin(x, name=None)
paddle.asinh(x, name=None)
paddle.assign(x, output=None)
paddle.atan(x, name=None)
paddle.atan2(x, y, name=None)
paddle.atanh(x, name=None)
paddle.batch(reader, batch_size, drop_last=False)
paddle.bernoulli(x, name=None)
paddle.bincount(x, weights=None, minlength=0, name=None)
paddle.bitwise_and(x, y, out=None, name=None)
paddle.bitwise_not(x, out=None, name=None)
paddle.bitwise_or(x, y, out=None, name=None)
paddle.bitwise_xor(x, y, out=None, name=None)
paddle.bmm(x, y, name=None)
paddle.broadcast_shape(x_shape, y_shape)
paddle.broadcast_tensors(input, name=None)
paddle.broadcast_to(x, shape, name=None)
paddle.bucketize(x, sorted_sequence, out_int32=False, right=False, name=None)
paddle.cast(x, dtype)
paddle.ceil(x, name=None)
paddle.check_shape(shape, op_name, expected_shape_type=(<class 'list'>, <class 'tuple'>, <class 'paddle.fluid.framework.Variable'>), expected_element_type=(<class 'int'>, <class 'paddle.fluid.framework.Variable'>), expected_tensor_dtype=('int32', 'int64'))
paddle.chunk(x, chunks, axis=0, name=None)
paddle.clip(x, min=None, max=None, name=None)
paddle.clone(x, name=None)
paddle.complex(real, imag, name=None)
paddle.concat(x, axis=0, name=None)
paddle.conj(x, name=None)
paddle.cos(x, name=None)
paddle.cosh(x, name=None)
paddle.count_nonzero(x, axis=None, keepdim=False, name=None)
paddle.create_parameter(shape, dtype, name=None, attr=None, is_bias=False, default_initializer=None)
paddle.crop(x, shape=None, offsets=None, name=None)
paddle.cross(x, y, axis=9, name=None)
paddle.cumprod(x, dim=None, dtype=None, name=None)
paddle.cumsum(x, axis=None, dtype=None, name=None)
paddle.DataParallel(layers, strategy=None, comm_buffer_size=25, last_comm_buffer_size=1, find_unused_parameters=False, group=None)
paddle.deg2rad(x, name=None)
paddle.diag(x, offset=0, padding_value=0, name=None)
paddle.diagflat(x, offset=0, name=None)
paddle.diagonal(x, offset=0, axis1=0, axis2=1, name=None)
paddle.diff(x, n=1, axis=-1, prepend=None, append=None, name=None)
paddle.digamma(x, name=None)
paddle.disable_signal_handler()
paddle.disable_static(place=None)
paddle.dist(x, y, p=2, name=None)
paddle.divide(x, y, name=None)
paddle.dot(x, y, name=None)
paddle.einsum(equation, *operands)
paddle.empty(shape, dtype=None, name=None)
paddle.empty_like(x, dtype=None, name=None)
paddle.enable_static()
paddle.equal(x, y, name=None)
paddle.equal_all(x, y, name=None)
paddle.erf(x, name=None)
paddle.erfinv(x, name=None)
paddle.exp(x, name=None)
paddle.expand(x, shape, name=None)
paddle.expand_as(x, y, name=None)
paddle.expm1(x, name=None)
paddle.eye(num_rows, num_columns=None, dtype=None, name=None)
paddle.flatten(x, start_axis=0, stop_axis=-1, name=None)
paddle.flip(x, axis, name=None)
paddle.floor(x, name=None)
paddle.floor_divide(x, y, name=None)
paddle.floor_mod(x, y, name=None)
paddle.flops(net, input_size, custom_ops=None, print_detail=False)
paddle.fmax(x, y, name=None)
paddle.fmin(x, y, name=None)
paddle.frac(x, name=None)
paddle.full(shape, fill_value, dtype=None, name=None)
paddle.full_like(x, fill_value, dtype=None, name=None)
paddle.gather(x, index, axis=None, name=None)
paddle.gather_nd(x, index, name=None)
paddle.gcd(x, y, name=None)
paddle.get_cuda_rng_state()
paddle.get_default_dtype()
paddle.get_flags(flags)
paddle.grad(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False, only_inputs=True, allow_unused=False, no_grad_vars=None)
paddle.greater_equal(x, y, name=None)
paddle.greater_than(x, y, name=None)
paddle.heaviside(x, y, name=None)
paddle.histogram(input, bins=100, min=0, max=0, name=None)
paddle.iinfo(dtype)
paddle.imag(x, name=None)
paddle.in_dynamic_mode()
paddle.increment(x, value=1.0, name=None)
paddle.index_add(x, index, axis, value, name=None)
paddle.index_add_(x, index, axis, value, name=None)
paddle.index_sample(x, index)
paddle.index_select(x, index, axis=0, name=None)
paddle.inner(x, y, name=None)
paddle.is_complex(x)
paddle.is_empty(x, name=None)
paddle.is_floating_point(x)
paddle.is_grad_enabled()
paddle.is_integer(x)
paddle.is_tensor(x)
paddle.isclose(x, y, rtol=1e-05, atol=1e-08, equal_nan=False, name=None)
paddle.isfinite(x, name=None)
paddle.isinf(x, name=None)
paddle.isnan(x, name=None)
paddle.kron(x, y, name=None)
paddle.kthvalue(x, k, axis=None, keepdim=False, name=None)
paddle.lcm(x, y, name=None)
paddle.lerp(x, y, weight, name=None)
paddle.less_equal(x, y, name=None)
paddle.less_than(x, y, name=None)
paddle.lgamma(x, name=None)
paddle.linspace(start, stop, num, dtype=None, name=None)
paddle.load(path, **configs)
paddle.log(x, name=None)
paddle.log10(x, name=None)
paddle.log1p(x, name=None)
paddle.log2(x, name=None)
paddle.logcumsumexp(x, axis=None, dtype=None, name=None)
paddle.logical_and(x, y, out=None, name=None)
paddle.logical_not(x, out=None, name=None)
paddle.logical_or(x, y, out=None, name=None)
paddle.logical_xor(x, y, out=None, name=None)
paddle.logit(x, eps=None, name=None)
paddle.logspace(start, stop, num, base=10.0, dtype=None, name=None)
paddle.logsumexp(x, axis=None, keepdim=False, name=None)
paddle.masked_select(x, mask, name=None)
paddle.matmul(x, y, transpose_x=False, transpose_y=False, name=None)
paddle.max(x, axis=None, keepdim=False, name=None)
paddle.maximum(x, y, name=None)
paddle.mean(x, axis=None, keepdim=False, name=None)
paddle.median(x, axis=None, keepdim=False, name=None)
paddle.meshgrid(*args, **kwargs)
paddle.min(x, axis=None, keepdim=False, name=None)
paddle.minimum(x, y, name=None)
paddle.mm(input, mat2, name=None)
paddle.mode(x, axis=-1, keepdim=False, name=None)
paddle.Model(network, inputs=None, labels=None)
paddle.moveaxis(x, source, destination, name=None)
paddle.multinomial(x, num_samples=1, replacement=False, name=None)
paddle.multiplex(inputs, index, name=None)
paddle.multiply(x, y, name=None)
paddle.mv(x, vec, name=None)
paddle.nanmean(x, axis=None, keepdim=False, name=None)
paddle.nanmedian(x, axis=None, keepdim=True, name=None)
paddle.nanquantile(x, q, axis=None, keepdim=False)
paddle.nansum(x, axis=None, dtype=None, keepdim=False, name=None)
paddle.neg(x, name=None)
paddle.nonzero(x, as_tuple=False)
paddle.normal(mean=0.0, std=1.0, shape=None, name=None)
paddle.not_equal(x, y, name=None)
paddle.numel(x, name=None)
paddle.ones(shape, dtype=None, name=None)
paddle.ones_like(x, dtype=None, name=None)
paddle.outer(x, y, name=None)
paddle.ParamAttr(name=None, initializer=None, learning_rate=1.0, regularizer=None, trainable=True, do_model_average=True, need_clip=True)
paddle.poisson(x, name=None)
paddle.pow(x, y, name=None)
paddle.prod(x, axis=None, keepdim=False, dtype=None, name=None)
paddle.put_along_axis(arr, indices, values, axis, reduce='assign')
paddle.quantile(x, q, axis=None, keepdim=False)
paddle.rad2deg(x, name=None)
paddle.rand(shape, dtype=None, name=None)
paddle.randint(low=0, high=None, shape=[1], dtype=None, name=None)
paddle.randint_like(x, low=0, high=None, dtype=None, name=None)
paddle.randn(shape, dtype=None, name=None)
paddle.randperm(n, dtype='int64', name=None)
paddle.rank(input)
paddle.real(x, name=None)
paddle.reciprocal(x, name=None)
paddle.renorm(x, p, axis, max_norm)
paddle.repeat_interleave(x, repeats, axis=None, name=None)
paddle.reshape(x, shape, name=None)
paddle.reshape_(x, shape, name=None)
paddle.roll(x, shifts, axis=None, name=None)
paddle.rot90(x, k=1, axes=[0, 1], name=None)
paddle.round(x, name=None)
paddle.rsqrt(x, name=None)
paddle.save(obj, path, protocol=4, **configs)
paddle.scale(x, scale=1.0, bias=0.0, bias_after_scale=True, act=None, name=None)
paddle.scatter(x, index, updates, overwrite=True, name=None)
paddle.scatter_(x, index, updates, overwrite=True, name=None)
paddle.scatter_nd(index, updates, shape, name=None)
paddle.scatter_nd_add(x, index, updates, name=None)
paddle.searchsorted(sorted_sequence, values, out_int32=False, right=False, name=None)
paddle.seed(seed)
paddle.set_cuda_rng_state(state_list)
paddle.set_default_dtype(d)
paddle.set_flags(flags)
paddle.set_grad_enabled(mode)
paddle.set_printoptions(precision=None, threshold=None, edgeitems=None, sci_mode=None, linewidth=None)
paddle.sgn(x, name=None)
paddle.shape(input)
paddle.shard_index(input, index_num, nshards, shard_id, ignore_value=-1)
paddle.sign(x, name=None)
paddle.sin(x, name=None)
paddle.sinh(x, name=None)
paddle.slice(input, axes, starts, ends)
paddle.sort(x, axis=-1, descending=False, name=None)
paddle.split(x, num_or_sections, axis=0, name=None)
paddle.sqrt(x, name=None)
paddle.square(x, name=None)
paddle.squeeze(x, axis=None, name=None)
paddle.squeeze_(x, axis=None, name=None)
paddle.stack(x, axis=0, name=None)
paddle.standard_normal(shape, dtype=None, name=None)
paddle.stanh(x, scale_a=0.67, scale_b=1.7159, name=None)
paddle.std(x, axis=None, unbiased=True, keepdim=False, name=None)
paddle.strided_slice(x, axes, starts, ends, strides, name=None)
paddle.subtract(x, y, name=None)
paddle.sum(x, axis=None, dtype=None, keepdim=False, name=None)
paddle.summary(net, input_size=None, dtypes=None, input=None)
paddle.t(input, name=None)
paddle.take(x, index, mode='raise', name=None)
paddle.take_along_axis(arr, indices, axis)
paddle.tan(x, name=None)
paddle.tanh(x, name=None)
paddle.tanh_(x, name=None)
paddle.Tensor abs(name=None)
paddle.tensordot(x, y, axes=2, name=None)
paddle.tile(x, repeat_times, name=None)
paddle.to_tensor(data, dtype=None, place=None, stop_gradient=True)
paddle.tolist(x)
paddle.topk(x, k, axis=None, largest=True, sorted=True, name=None)
paddle.trace(x, offset=0, axis1=0, axis2=1, name=None)
paddle.transpose(x, perm, name=None)
paddle.tril(x, diagonal=0, name=None)
paddle.tril_indices(row, col, offset=0, dtype='int64')
paddle.triu(x, diagonal=0, name=None)
paddle.triu_indices(row, col=None, offset=0, dtype='int64')
paddle.trunc(input, name=None)
paddle.unbind(input, axis=0)
paddle.uniform(shape, dtype=None, min=-1.0, max=1.0, seed=0, name=None)
paddle.unique(x, return_index=False, return_inverse=False, return_counts=False, axis=None, dtype='int64', name=None)
paddle.unique_consecutive(x, return_inverse=False, return_counts=False, axis=None, dtype='int64', name=None)
paddle.unsqueeze(x, axis, name=None)
paddle.unsqueeze_(x, axis, name=None)
paddle.unstack(x, axis=0, num=None)
paddle.var(x, axis=None, unbiased=True, keepdim=False, name=None)
paddle.where(condition, x=None, y=None, name=None)
paddle.zeros(shape, dtype=None, name=None)
paddle.zeros_like(x, dtype=None, name=None)
paddle.amp.auto_cast(enable=True, custom_white_list=None, custom_black_list=None, level='O1', dtype='float16')
paddle.amp.decorate(models, optimizers=None, level='O1', master_weight=None, save_dtype=None)
paddle.amp.GradScaler(enable=True, init_loss_scaling=32768.0, incr_ratio=2.0, decr_ratio=0.5, incr_every_n_steps=1000, decr_every_n_nan_or_inf=2, use_dynamic_loss_scaling=True)
paddle.audio.save(filepath: str, src: paddle.Tensor, sample_rate: int, channels_first: bool = True, encoding: Optional[str] = None, bits_per_sample: Optional[int] = 16)
paddle.autograd.backward(tensors, grad_tensors=None, retain_graph=False)
paddle.callbacks.EarlyStopping(monitor='loss', mode='auto', patience=0, verbose=1, min_delta=0, baseline=None, save_best_model=True)
paddle.callbacks.LRScheduler(by_step=True, by_epoch=False)
paddle.callbacks.ModelCheckpoint(save_freq=1, save_dir=None)
paddle.callbacks.ProgBarLogger(log_freq=1, verbose=2)
paddle.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)
paddle.callbacks.VisualDL(log_dir)
paddle.device.get_all_custom_device_type()
paddle.device.get_all_device_type()
paddle.device.get_available_custom_device()
paddle.device.get_available_device()
paddle.device.get_cudnn_version()
paddle.device.get_device()
paddle.device.IPUPlace()
paddle.device.is_compiled_with_cinn()
paddle.device.is_compiled_with_cuda()
paddle.device.is_compiled_with_ipu()
paddle.device.is_compiled_with_mlu()
paddle.device.is_compiled_with_npu()
paddle.device.is_compiled_with_rocm()
paddle.device.is_compiled_with_xpu()
paddle.device.MLUPlace(dev_id)
paddle.device.set_device(device)
paddle.device.XPUPlace(dev_id)
paddle.distributed.all_gather(tensor_list, tensor, group=None, sync_op=True)
paddle.distributed.all_gather_object(object_list, obj, group=None)
paddle.distributed.all_reduce(tensor, op=0, group=None, sync_op=True)
paddle.distributed.alltoall(in_tensor_list, out_tensor_list, group=None, sync_op=True)
paddle.distributed.alltoall_single(in_tensor, out_tensor, in_split_sizes=None, out_split_sizes=None, group=None, sync_op=True)
paddle.distributed.barrier(group=None)
paddle.distributed.broadcast(tensor, src, group=None, sync_op=True)
paddle.distributed.CountFilterEntry(count_filter)
paddle.distributed.destroy_process_group(group=None)
paddle.distributed.get_group(id=0)
paddle.distributed.get_rank(group=None)
paddle.distributed.get_world_size(group=None)
paddle.distributed.gloo_barrier()
paddle.distributed.gloo_init_parallel_env(rank_id, rank_num, server_endpoint)
paddle.distributed.gloo_release()
paddle.distributed.init_parallel_env()
paddle.distributed.irecv(tensor, src=None, group=None)
paddle.distributed.is_initialized()
paddle.distributed.isend(tensor, dst, group=None)
paddle.distributed.launch()
paddle.distributed.new_group(ranks=None, backend=None, timeout=datetime.timedelta(seconds=1800))
paddle.distributed.ProbabilityEntry(probability)
paddle.distributed.recv(tensor, src=0, group=None, sync_op=True)
paddle.distributed.reduce(tensor, dst, op=0, group=None, sync_op=True)
paddle.distributed.reduce_scatter(tensor, tensor_list, op=0, group=None, sync_op=True)
paddle.distributed.scatter(tensor, tensor_list=None, src=0, group=None, sync_op=True)
paddle.distributed.send(tensor, dst=0, group=None, sync_op=True)
paddle.distributed.ShowClickEntry(show_name, click_name)
paddle.distributed.spawn(func, args=(), nprocs=-1, join=True, daemon=False, **options)
paddle.distributed.split(x, size, operation, axis=0, num_partitions=1, gather_out=True, weight_attr=None, bias_attr=None, name=None)
paddle.distributed.wait(tensor, group=None, use_calc_stream=True)
paddle.distribution.AffineTransform(loc, scale)
paddle.distribution.Beta(alpha, beta)
paddle.distribution.Categorical(logits, name=None)
paddle.distribution.ChainTransform(transforms)
paddle.distribution.Dirichlet(concentration)
paddle.distribution.Distribution(batch_shape=(), event_shape=())
paddle.distribution.ExponentialFamily(batch_shape=(), event_shape=())
paddle.distribution.Independent(base, reinterpreted_batch_rank)
paddle.distribution.IndependentTransform(base, reinterpreted_batch_rank)
paddle.distribution.kl_divergence(p, q)
paddle.distribution.Multinomial(total_count, probs)
paddle.distribution.Normal(loc, scale, name=None)
paddle.distribution.PowerTransform(power)
paddle.distribution.register_kl(cls_p, cls_q)
paddle.distribution.ReshapeTransform(in_event_shape, out_event_shape)
paddle.distribution.StackTransform(transforms, axis=0)
paddle.distribution.TransformedDistribution(base, transforms)
paddle.distribution.Uniform(low, high, name=None)
paddle.fft.fft(x, n=None, axis=-1, norm='backward', name=None)
paddle.fft.fft2(x, s=None, axes=(-2,-1), norm='backward', name=None)
paddle.fft.fftfreq(n, d=1.0, dtype=None, name=None)
paddle.fft.fftn(x, s=None, axes=None, norm='backward', name=None)
paddle.fft.fftshift(x, axes=None, name=None)
paddle.fft.hfft(x, n=None, axis=-1, norm='backward', name=None)
paddle.fft.hfft2(x, s=None, axes=(-2,-1), norm='backward', name=None)
paddle.fft.hfftn(x, s=None, axes=None, norm='backward', name=None)
paddle.fft.ifft(x, n=None, axis=-1, norm='backward', name=None)
paddle.fft.ifft2(x, s=None, axes=(-2,-1), norm='backward', name=None)
paddle.fft.ifftn(x, s=None, axes=None, norm='backward', name=None)
paddle.fft.ifftshift(x, axes=None, name=None)
paddle.fft.ihfft(x, n=None, axis=-1, norm='backward', name=None)
paddle.fft.ihfft2(x, s=None, axes=(-2,-1), norm='backward', name=None)
paddle.fft.ihfftn(x, s=None, axes=None, norm='backward', name=None)
paddle.fft.irfft(x, n=None, axis=-1, norm='backward', name=None)
paddle.fft.irfft2(x, s=None, axes=(-2,-1), norm='backward', name=None)
paddle.fft.irfftn(x, s=None, axes=None, norm='backward', name=None)
paddle.fft.rfft(x, n=None, axis=-1, norm='backward', name=None)
paddle.fft.rfft2(x, s=None, axes=(-2,-1), norm='backward', name=None)
paddle.fft.rfftfreq(n, d=1.0, dtype=None, name=None)
paddle.fft.rfftn(x, s=None, axes=None, norm='backward', name=None)
paddle.fluid.data(name, shape, dtype='float32', lod_level=0)
paddle.geometric.reindex_graph(x, neighbors, count, value_buffer=None, index_buffer=None, name=None)
paddle.geometric.reindex_heter_graph(x, neighbors, count, value_buffer=None, index_buffer=None, name=None)
paddle.geometric.sample_neighbors(row, colptr, input_nodes, sample_size=-1, eids=None, return_eids=False, perm_buffer=None, name=None)
paddle.geometric.segment_max(data, segment_ids, name=None)
paddle.geometric.segment_mean(data, segment_ids, name=None)
paddle.geometric.segment_min(data, segment_ids, name=None)
paddle.geometric.segment_sum(data, segment_ids, name=None)
paddle.geometric.send_u_recv(x, src_index, dst_index, reduce_op='sum', out_size=None, name=None)
paddle.geometric.send_ue_recv(x, y, src_index, dst_index, message_op='add', reduce_op='sum', out_size=None, name=None)
paddle.geometric.send_uv(x, y, src_index, dst_index, message_op='add', name=None)
paddle.hub.help(repo_dir, model, source='github', force_reload=False)
paddle.hub.list(repo_dir, source='github', force_reload=False)
paddle.hub.load(repo_dir, model, source='github', force_reload=False, **kwargs)
paddle.incubate.graph_khop_sampler(row, colptr, input_nodes, sample_sizes, sorted_eids=None, return_eids=False, name=None)
paddle.incubate.graph_reindex(x, neighbors, count, value_buffer=None, index_buffer=None, flag_buffer_hashtable=False, name=None)
paddle.incubate.graph_sample_neighbors(row, colptr, input_nodes, eids=None, perm_buffer=None, sample_size=-1, return_eids=False, flag_perm_buffer=False, name=None)
paddle.incubate.graph_send_recv(x, src_index, dst_index, pool_type='sum', out_size=None, name=None)
paddle.incubate.identity_loss(x, reduction='none')
paddle.incubate.LookAhead(inner_optimizer, alpha=0.5, k=5, name=None)
paddle.incubate.ModelAverage(average_window_rate, parameters=None, min_average_window=10000, max_average_window=10000, name=None)
paddle.incubate.segment_max(data, segment_ids, name=None)
paddle.incubate.segment_mean(data, segment_ids, name=None)
paddle.incubate.segment_min(data, segment_ids, name=None)
paddle.incubate.segment_sum(data, segment_ids, name=None)
paddle.incubate.softmax_mask_fuse(x, mask, name=None)
paddle.incubate.softmax_mask_fuse_upper_triangle(x)
paddle.inference.convert_to_mixed_precision(model_file: str, params_file: str, mixed_model_file: str, mixed_params_file: str, mixed_precision: paddle.fluid.libpaddle.AnalysisConfig.Precision, backend: paddle.fluid.libpaddle.PaddlePlace, keep_io_types: bool = True, black_list: Set = {})
paddle.io.BatchSampler(dataset=None, sampler=None, shuffle=False, batch_size=1, drop_last=False)
paddle.io.ChainDataset(datasets)
paddle.io.ComposeDataset(datasets)
paddle.io.DataLoader(dataset, feed_list=None, places=None, return_list=True, batch_sampler=None, batch_size=1, shuffle=False, drop_last=False, collate_fn=None, num_workers=0, use_buffer_reader=True, prefetch_factor=2, use_shared_memory=True, timeout=0, worker_init_fn=None, persistent_workers=False)
paddle.io.DistributedBatchSampler(dataset, batch_size, num_replicas=None, rank=None, shuffle=False, drop_last=False)
paddle.io.get_worker_info()
paddle.io.random_split(dataset, lengths, generator=None)
paddle.io.RandomSampler(data_source, replacement=False, num_samples=None, generator=None)
paddle.io.Sampler(data_source=None)
paddle.io.SequenceSampler(data_source)
paddle.io.Subset(dataset, indices)
paddle.io.TensorDataset(tensors)
paddle.io.WeightedRandomSampler(weights, num_samples, replacement=True)
paddle.jit.load(path, **configs)
paddle.jit.not_to_static(func=None)
paddle.jit.ProgramTranslator(**kwargs)
paddle.jit.save(layer, path, input_spec=None, **configs)
paddle.jit.set_code_level(level=100, also_to_stdout=False)
paddle.jit.set_verbosity(level=0, also_to_stdout=False)
paddle.jit.to_static(function=None, input_spec=None, build_strategy=None, property=False)
paddle.jit.TracedLayer(program, parameters, feed_names, fetch_names)
paddle.jit.TranslatedLayer(programs, persistable_vars)
paddle.linalg.cholesky(x, upper=False, name=None)
paddle.linalg.cholesky_solve(x, y, upper=False, name=None)
paddle.linalg.cond(x, p=None, name=None)
paddle.linalg.corrcoef(x, rowvar=True, name=None)
paddle.linalg.cov(x, rowvar=True, ddof=True, fweights=None, aweights=None, name=None)
paddle.linalg.det(x, name=None)
paddle.linalg.eig(x, name=None)
paddle.linalg.eigh(x, UPLO='L', name=None)
paddle.linalg.eigvals(x, name=None)
paddle.linalg.eigvalsh(x, UPLO='L', name=None)
paddle.linalg.inv(x, name=None)
paddle.linalg.lstsq(x, y, rcond=None, driver=None, name=None)
paddle.linalg.lu(x, pivot=True, get_infos=False, name=None)
paddle.linalg.lu_unpack(x, y, unpack_ludata=True, unpack_pivots=True, name=None)
paddle.linalg.matrix_power(x, n, name=None)
paddle.linalg.matrix_rank(x, tol=None, hermitian=False, name=None)
paddle.linalg.multi_dot(x, name=None)
paddle.linalg.norm(x, p='fro', axis=None, keepdim=False, name=None)
paddle.linalg.pinv(x, rcond=1e-15, hermitian=False, name=None)
paddle.linalg.qr(x, mode='reduced', name=None)
paddle.linalg.slogdet(x, name=None)
paddle.linalg.solve(x, y, name=None)
paddle.linalg.svd(x, full_matrices=False, name=None)
paddle.linalg.triangular_solve(x, y, upper=True, transpose=False, unitriangular=False, name=None)
paddle.metric.Accuracy(topk=(1,), name=None, *args, **kwargs)
paddle.metric.accuracy(input, label, k=1, correct=None, total=None, name=None)
paddle.metric.Auc(curve='ROC', num_thresholds=4095, name='auc', *args, **kwargs)
paddle.metric.Precision(name='precision', *args, **kwargs)
paddle.metric.Recall(name='recall', *args, **kwargs)
paddle.nn.AdaptiveAvgPool1D(output_size, name=None)
paddle.nn.AdaptiveAvgPool2D(output_size, data_format='NCHW', name=None)
paddle.nn.AdaptiveAvgPool3D(output_size, data_format='NCDHW', name=None)
paddle.nn.AdaptiveMaxPool1D(output_size, return_mask=False, name=None)
paddle.nn.AdaptiveMaxPool2D(output_size, return_mask=False, name=None)
paddle.nn.AdaptiveMaxPool3D(output_size, return_mask=False, name=None)
paddle.nn.AlphaDropout(p=0.5, name=None)
paddle.nn.AvgPool1D(kernel_size, stride=None, padding=0, exclusive=True, ceil_mode=False, name=None)
paddle.nn.AvgPool2D(kernel_size, stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format='NCHW', name=None)
paddle.nn.AvgPool3D(kernel_size, stride=None, padding=0, ceil_mode=False, exclusive=True, divisor_override=None, data_format='NCDHW', name=None)
paddle.nn.BatchNorm(num_channels, act=None, is_test=False, momentum=0.9, epsilon=1e-05, param_attr=None, bias_attr=None, dtype='float32', data_layout='NCHW', in_place=False, moving_mean_name=None, moving_variance_name=None, do_model_average_for_mean_and_var=True, use_global_stats=False, trainable_statistics=False)
paddle.nn.BatchNorm1D(num_features, momentum=0.9, epsilon=1e-05, weight_attr=None, bias_attr=None, data_format='NCL', use_global_stats=None, name=None)
paddle.nn.BatchNorm2D(num_features, momentum=0.9, epsilon=1e-05, weight_attr=None, bias_attr=None, data_format='NCHW', use_global_stats=None, name=None)
paddle.nn.BatchNorm3D(num_features, momentum=0.9, epsilon=1e-05, weight_attr=None, bias_attr=None, data_format='NCDHW', use_global_stats=None, name=None)
paddle.nn.BCELoss(weight=None, reduction='mean', name=None)
paddle.nn.BCEWithLogitsLoss(weight=None, reduction='mean', pos_weight=None, name=None)
paddle.nn.BeamSearchDecoder(cell, start_token, end_token, beam_size, embedding_fn=None, output_fn=None)
paddle.nn.Bilinear(in1_features, in2_features, out_features, weight_attr=None, bias_attr=None, name=None)
paddle.nn.BiRNN(cell_fw, cell_bw, time_major=False)
paddle.nn.CELU(alpha=1.0, name=None)
paddle.nn.ChannelShuffle(groups, data_format='NCHW', name=None)
paddle.nn.ClipGradByGlobalNorm(clip_norm, group_name='default_group', auto_skip_clip=False)
paddle.nn.ClipGradByNorm(clip_norm)
paddle.nn.ClipGradByValue(max, min=None)
paddle.nn.Conv1D(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', weight_attr=None, bias_attr=None, data_format='NCL')
paddle.nn.Conv1DTranspose(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, dilation=1, weight_attr=None, bias_attr=None, data_format='NCL')
paddle.nn.Conv2D(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', weight_attr=None, bias_attr=None, data_format='NCHW')
paddle.nn.Conv2DTranspose(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, dilation=1, groups=1, weight_attr=None, bias_attr=None, data_format='NCHW')
paddle.nn.Conv3D(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', weight_attr=None, bias_attr=None, data_format='NCDHW')
paddle.nn.Conv3DTranspose(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, dilation=1, groups=1, weight_attr=None, bias_attr=None, data_format='NCDHW')
paddle.nn.CosineEmbeddingLoss(margin=0, reduction='mean', name=None)
paddle.nn.CosineSimilarity(axis=1, eps=1e-08)
paddle.nn.CrossEntropyLoss(weight=None, ignore_index=-100, reduction='mean', soft_label=False, axis=-1, use_softmax=True, name=None)
paddle.nn.CTCLoss(blank=0, reduction='mean')
paddle.nn.Dropout(p=0.5, axis=None, mode='upscale_in_train', name=None)
paddle.nn.Dropout2D(p=0.5, data_format='NCHW', name=None)
paddle.nn.Dropout3D(p=0.5, data_format='NCDHW', name=None)
paddle.nn.dynamic_decode(decoder, inits=None, max_step_num=None, output_time_major=False, impute_finished=False, is_test=False, return_length=False, **kwargs)
paddle.nn.ELU(alpha=1.0, name=None)
paddle.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, sparse=False, weight_attr=None, name=None)
paddle.nn.Flatten(start_axis=1, stop_axis=-1)
paddle.nn.Fold(output_sizes, kernel_sizes, dilations=1, paddings=0, strides=1, name=None)
paddle.nn.GELU(approximate=False, name=None)
paddle.nn.GroupNorm(num_groups, num_channels, epsilon=1e-05, weight_attr=None, bias_attr=None, data_format='NCHW', name=None)
paddle.nn.GRU(input_size, hidden_size, num_layers=1, direction='forward', time_major=False, dropout=0.0, weight_ih_attr=None, weight_hh_attr=None, bias_ih_attr=None, bias_hh_attr=None, name=None)
paddle.nn.GRUCell(input_size, hidden_size, weight_ih_attr=None, weight_hh_attr=None, bias_ih_attr=None, bias_hh_attr=None, name=None)
paddle.nn.Hardshrink(threshold=0.5, name=None)
paddle.nn.Hardsigmoid(name=None)
paddle.nn.Hardswish(name=None)
paddle.nn.Hardtanh(min=-1.0, max=1.0, name=None)
paddle.nn.HingeEmbeddingLoss(margin=1.0, reduction='mean', name=None)
paddle.nn.HSigmoidLoss(feature_size, num_classes, weight_attr=None, bias_attr=None, is_custom=False, is_sparse=False, name=None)
paddle.nn.Identity(*args, **kwargs)
paddle.nn.InstanceNorm1D(num_features, epsilon=1e-05, momentum=0.9, weight_attr=None, bias_attr=None, data_format='NCHW', name=None)
paddle.nn.InstanceNorm2D(num_features, epsilon=1e-05, momentum=0.9, weight_attr=None, bias_attr=None, data_format='NCHW', name=None)
paddle.nn.InstanceNorm3D(num_features, epsilon=1e-05, momentum=0.9, weight_attr=None, bias_attr=None, data_format='NCHW', name=None)
paddle.nn.KLDivLoss(reduction='mean')
paddle.nn.L1Loss(reduction='mean', name=None)
paddle.nn.Layer(name_scope=None, dtype='float32')
paddle.nn.LayerDict(sublayers=None)
paddle.nn.LayerList(sublayers=None)
paddle.nn.LayerNorm(normalized_shape, epsilon=1e-05, weight_attr=None, bias_attr=None, name=None)
paddle.nn.LeakyReLU(negative_slope=0.01, name=None)
paddle.nn.Linear(in_features, out_features, weight_attr=None, bias_attr=None, name=None)
paddle.nn.LocalResponseNorm(size, alpha=0.0001, beta=0.75, k=1.0, data_format='NCHW', name=None)
paddle.nn.LogSigmoid(name=None)
paddle.nn.LogSoftmax(axis=-1, name=None)
paddle.nn.LSTM(input_size, hidden_size, num_layers=1, direction='forward', time_major=False, dropout=0.0, weight_ih_attr=None, weight_hh_attr=None, bias_ih_attr=None, bias_hh_attr=None, name=None)
paddle.nn.LSTMCell(input_size, hidden_size, weight_ih_attr=None, weight_hh_attr=None, bias_ih_attr=None, bias_hh_attr=None, name=None)
paddle.nn.MarginRankingLoss(margin=0.0, reduction='mean', name=None)
paddle.nn.Maxout(groups, axis=1, name=None)
paddle.nn.MaxPool1D(kernel_size, stride=None, padding=0, return_mask=False, ceil_mode=False, name=None)
paddle.nn.MaxPool2D(kernel_size, stride=None, padding=0, return_mask=False, ceil_mode=False, data_format='NCHW', name=None)
paddle.nn.MaxPool3D(kernel_size, stride=None, padding=0, return_mask=False, ceil_mode=False, data_format='NCDHW', name=None)
paddle.nn.MaxUnPool1D(kernel_size, stride=None, padding=0, data_format='NCL', output_size=None, name=None)
paddle.nn.MaxUnPool2D(kernel_size, stride=None, padding=0, data_format='NCHW', output_size=None, name=None)
paddle.nn.MaxUnPool3D(kernel_size, stride=None, padding=0, data_format='NCDHW', output_size=None, name=None)
paddle.nn.Mish(name=None)
paddle.nn.MSELoss(reduction='mean')
paddle.nn.MultiHeadAttention(embed_dim, num_heads, dropout=0.0, kdim=None, vdim=None, need_weights=False, weight_attr=None, bias_attr=None)
paddle.nn.MultiLabelSoftMarginLoss(weight=None, reduction='mean', name=None)
paddle.nn.NLLLoss(weight=None, ignore_index=-100, reduction='mean', name=None)
paddle.nn.Pad1D(padding, mode='constant', value=0.0, data_format='NCL', name=None)
paddle.nn.Pad2D(padding, mode='constant', value=0.0, data_format='NCHW', name=None)
paddle.nn.Pad3D(padding, mode='constant', value=0.0, data_format='NCDHW', name=None)
paddle.nn.PairwiseDistance(p=2.0, epsilon=1e-06, keepdim=False, name=None)
paddle.nn.ParameterList(parameters=None)
paddle.nn.PixelShuffle(upscale_factor, data_format='NCHW', name=None)
paddle.nn.PixelUnshuffle(downscale_factor, data_format='NCHW', name=None)
paddle.nn.PReLU(num_parameters=1, init=0.25, weight_attr=None, data_format='NCHW', name=None)
paddle.nn.ReLU(name=None)
paddle.nn.ReLU6(name=None)
paddle.nn.RNN(cell, is_reverse=False, time_major=False)
paddle.nn.RNNCellBase(name_scope=None, dtype='float32')
paddle.nn.RReLU(lower=0.125, upper=0.3333333333333333, name=None)
paddle.nn.SELU(scale=1.0507009873554805, alpha=1.6732632423543772, name=None)
paddle.nn.Sequential(*layers)
paddle.nn.Sigmoid(name=None)
paddle.nn.Silu(name=None)
paddle.nn.SimpleRNN(input_size, hidden_size, num_layers=1, direction='forward', time_major=False, dropout=0.0, activation='tanh', weight_ih_attr=None, weight_hh_attr=None, bias_ih_attr=None, bias_hh_attr=None, name=None)
paddle.nn.SimpleRNNCell(input_size, hidden_size, activation='tanh', weight_ih_attr=None, weight_hh_attr=None, bias_ih_attr=None, bias_hh_attr=None, name=None)
paddle.nn.SmoothL1Loss(reduction='mean', delta=1.0, name=None)
paddle.nn.SoftMarginLoss(reduction='mean', name=None)
paddle.nn.Softmax(axis=-1, name=None)
paddle.nn.Softmax2D(name=None)
paddle.nn.Softplus(beta=1, threshold=20, name=None)
paddle.nn.Softshrink(threshold=0.5, name=None)
paddle.nn.Softsign(name=None)
paddle.nn.SpectralNorm(weight_shape, dim=0, power_iters=1, eps=1e-12, dtype='float32')
paddle.nn.Swish(name=None)
paddle.nn.SyncBatchNorm(num_features, momentum=0.9, epsilon=1e-05, weight_attr=None, bias_attr=None, data_format='NCHW', name=None)
paddle.nn.Tanh(name=None)
paddle.nn.Tanhshrink(name=None)
paddle.nn.ThresholdedReLU(threshold=1.0, name=None)
paddle.nn.Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1, activation='relu', attn_dropout=None, act_dropout=None, normalize_before=False, weight_attr=None, bias_attr=None, custom_encoder=None, custom_decoder=None)
paddle.nn.TransformerDecoder(decoder_layer, num_layers, norm=None)
paddle.nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout=0.1, activation='relu', attn_dropout=None, act_dropout=None, normalize_before=False, weight_attr=None, bias_attr=None)
paddle.nn.TransformerEncoder(encoder_layer, num_layers, norm=None)
paddle.nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout=0.1, activation='relu', attn_dropout=None, act_dropout=None, normalize_before=False, weight_attr=None, bias_attr=None)
paddle.nn.TripletMarginLoss(margin=1.0, p=2.0, epsilon=1e-06, swap=False, reduction='mean', name=None)
paddle.nn.TripletMarginWithDistanceLoss(distance_function=None, margin=1.0, swap=False, reduction: str = 'mean', name=None)
paddle.nn.Unfold(kernel_sizes, dilations=1, paddings=0, strides=1, name=None)
paddle.nn.Upsample(size=None, scale_factor=None, mode='nearest', align_corners=False, align_mode=0, data_format='NCHW', name=None)
paddle.nn.UpsamplingBilinear2D(size=None, scale_factor=None, data_format='NCHW', name=None)
paddle.nn.UpsamplingNearest2D(size=None, scale_factor=None, data_format='NCHW', name=None)
paddle.nn.ZeroPad2D(padding, data_format='NCHW', name=None)
paddle.onnx.export(layer, path, input_spec=None, opset_version=9, **configs)
paddle.optimizer.Adadelta(learning_rate=0.001, epsilon=1e-06, rho=0.95, parameters=None, weight_decay=None, grad_clip=None, name=None)
paddle.optimizer.Adagrad(learning_rate, epsilon=1e-06, parameters=None, weight_decay=None, grad_clip=None, name=None, initial_accumulator_value=0.0)
paddle.optimizer.Adam(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, parameters=None, weight_decay=None, grad_clip=None, lazy_mode=False, multi_precision=False, use_multi_tensor=False, name=None)
paddle.optimizer.Adamax(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, parameters=None, weight_decay=None, grad_clip=None, name=None)
paddle.optimizer.AdamW(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, parameters=None, weight_decay=0.01, lr_ratio=None, apply_decay_param_fun=None, grad_clip=None, lazy_mode=False, multi_precision=False, name=None)
paddle.optimizer.Lamb(learning_rate=0.001, lamb_weight_decay=0.01, beta1=0.9, beta2=0.999, epsilon=1e-06, parameters=None, grad_clip=None, exclude_from_weight_decay_fn=None, multi_precision=False, name=None)
paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=None, use_nesterov=False, weight_decay=None, grad_clip=None, multi_precision=False, rescale_grad=1.0, use_multi_tensor=False, name=None)
paddle.optimizer.Optimizer(learning_rate, parameters=None, weight_decay=None, grad_clip=None, name=None)
paddle.optimizer.RMSProp(learning_rate, rho=0.95, epsilon=1e-06, momentum=0.0, centered=False, parameters=None, weight_decay=None, grad_clip=None, name=None)
paddle.optimizer.SGD(learning_rate=0.001, parameters=None, weight_decay=None, grad_clip=None, multi_precision=False, name=None)
paddle.profiler.load_profiler_result(filename: str)
paddle.profiler.Profiler(*, targets: Optional[Iterable[paddle.profiler.profiler.ProfilerTarget]] = None, scheduler: Optional[Union[Callable[[int], paddle.profiler.profiler.ProfilerState], tuple]] = None, on_trace_ready: Optional[Callable[[...], Any]] = None, record_shapes: Optional[bool] = False, profile_memory=False, timer_only: Optional[bool] = False, emit_nvtx: Optional[bool] = False, custom_device_types: Optional[list] = [])
paddle.profiler.ProfilerState(value)
paddle.profiler.ProfilerTarget(value)
paddle.profiler.RecordEvent(name: str, event_type: paddle.fluid.libpaddle.TracerEventType = TracerEventType.PythonUserDefined)
paddle.profiler.SortedKeys(value)
paddle.profiler.SummaryView(value)
paddle.regularizer.L1Decay(coeff=0.0)
paddle.regularizer.L2Decay(coeff=0.0)
paddle.signal.istft(x, n_fft, hop_length=None, win_length=None, window=None, center=True, normalized=False, onesided=True, length=None, return_complex=False, name=None)
paddle.signal.stft(x, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True, name=None)
paddle.sparse.abs(x, name=None)
paddle.sparse.add(x, y, name=None)
paddle.sparse.addmm(input, x, y, beta=1.0, alpha=1.0, name=None)
paddle.sparse.asin(x, name=None)
paddle.sparse.asinh(x, name=None)
paddle.sparse.atan(x, name=None)
paddle.sparse.atanh(x, name=None)
paddle.sparse.cast(x, index_dtype=None, value_dtype=None, name=None)
paddle.sparse.coalesce(x, name=None)
paddle.sparse.deg2rad(x, name=None)
paddle.sparse.divide(x, y, name=None)
paddle.sparse.expm1(x, name=None)
paddle.sparse.is_same_shape(x, y)
paddle.sparse.log1p(x, name=None)
paddle.sparse.masked_matmul(x, y, mask, name=None)
paddle.sparse.matmul(x, y, name=None)
paddle.sparse.multiply(x, y, name=None)
paddle.sparse.mv(x, vec, name=None)
paddle.sparse.neg(x, name=None)
paddle.sparse.pow(x, factor, name=None)
paddle.sparse.rad2deg(x, name=None)
paddle.sparse.reshape(x, shape, name=None)
paddle.sparse.sin(x, name=None)
paddle.sparse.sinh(x, name=None)
paddle.sparse.sparse_coo_tensor(indices, values, shape=None, dtype=None, place=None, stop_gradient=True)
paddle.sparse.sparse_csr_tensor(crows, cols, values, shape, dtype=None, place=None, stop_gradient=True)
paddle.sparse.sqrt(x, name=None)
paddle.sparse.square(x, name=None)
paddle.sparse.subtract(x, y, name=None)
paddle.sparse.tan(x, name=None)
paddle.sparse.tanh(x, name=None)
paddle.sparse.transpose(x, perm, name=None)
paddle.static.accuracy(input, label, k=1, correct=None, total=None)
paddle.static.append_backward(loss, parameter_list=None, no_grad_set=None, callbacks=None, checkpoints=None, distop_context=None)
paddle.static.auc(input, label, curve='ROC', num_thresholds=4095, topk=1, slide_steps=1, ins_tag_weight=None)
paddle.static.CompiledProgram(program_or_graph, build_strategy=None)
paddle.static.cpu_places(device_count=None)
paddle.static.create_global_var(shape, value, dtype, persistable=False, force_cpu=False, name=None)
paddle.static.ctr_metric_bundle(input, label, ins_tag_weight=None)
paddle.static.cuda_places(device_ids=None)
paddle.static.data(name, shape, dtype=None, lod_level=0)
paddle.static.default_main_program()
paddle.static.default_startup_program()
paddle.static.deserialize_persistables(program, data, executor)
paddle.static.deserialize_program(data)
paddle.static.device_guard(device=None)
paddle.static.Executor(place=None)
paddle.static.exponential_decay(learning_rate, decay_steps, decay_rate, staircase=False)
paddle.static.ExponentialMovingAverage(decay=0.999, thres_steps=None, name=None)
paddle.static.global_scope()
paddle.static.gradients(targets, inputs, target_gradients=None, no_grad_set=None)
paddle.static.InputSpec(shape, dtype='float32', name=None)
paddle.static.ipu_shard_guard(index=-1, stage=-1)
paddle.static.IpuCompiledProgram(program=None, scope=None, ipu_strategy=None)
paddle.static.load(program, model_path, executor=None, var_list=None)
paddle.static.load_from_file(path)
paddle.static.load_inference_model(path_prefix, executor, **kwargs)
paddle.static.load_program_state(model_path, var_list=None)
paddle.static.mlu_places(device_ids=None)
paddle.static.name_scope(prefix=None)
paddle.static.normalize_program(program, feed_vars, fetch_vars)
paddle.static.npu_places(device_ids=None)
paddle.static.ParallelExecutor(use_cuda, loss_name=None, main_program=None, share_vars_from=None, exec_strategy=None, build_strategy=None, num_trainers=1, trainer_id=0, scope=None)
paddle.static.Print(input, first_n=-1, message=None, summarize=20, print_tensor_name=True, print_tensor_type=True, print_tensor_shape=True, print_tensor_layout=True, print_tensor_lod=True, print_phase='both')
paddle.static.program_guard(main_program, startup_program=None)
paddle.static.py_func(func, x, out, backward_func=None, skip_vars_in_backward_input=None)
paddle.static.save(program, model_path, protocol=4, **configs)
paddle.static.save_inference_model(path_prefix, feed_vars, fetch_vars, executor, **kwargs)
paddle.static.save_to_file(path, content)
paddle.static.scope_guard(scope)
paddle.static.serialize_persistables(feed_vars, fetch_vars, executor, **kwargs)
paddle.static.serialize_program(feed_vars, fetch_vars, **kwargs)
paddle.static.set_ipu_shard(call_func, index=-1, stage=-1)
paddle.static.set_program_state(program, state_dict)
paddle.static.Variable(block, type=VarType.LOD_TENSOR, name=None, shape=None, dtype=None, lod_level=None, capacity=None, persistable=None, error_clip=None, stop_gradient=False, is_data=False, need_check_feed=False, belong_to_optimizer=False, **kwargs)
paddle.static.WeightNormParamAttr(dim=None, name=None, initializer=None, learning_rate=1.0, regularizer=None, trainable=True, do_model_average=False, need_clip=True)
paddle.static.xpu_places(device_ids=None)
paddle.sysconfig.get_include()
paddle.sysconfig.get_lib()
paddle.Tensor.add_(x, y, name=None)
paddle.Tensor.astype(self, dtype)
paddle.Tensor.backward(self, grad_tensor=None, retain_graph=False)
paddle.Tensor.ceil_(x, name=None)
paddle.Tensor.clear_grad(self)
paddle.Tensor.clip_(x, min=None, max=None, name=None)
paddle.Tensor.clone(self)
paddle.Tensor.cpu(self)
paddle.Tensor.cuda(self, device_id=None, blocking=True)
paddle.Tensor.dim(x)
paddle.Tensor.erfinv_(x, name=None)
paddle.Tensor.exp_(x, name=None)
paddle.Tensor.exponential_(x, lam=1.0, name=None)
paddle.Tensor.fill_(x, value)
paddle.Tensor.fill_diagonal_(x, value, offset=0, wrap=False, name=None)
paddle.Tensor.fill_diagonal_tensor(x, y, offset=0, dim1=0, dim2=1, name=None)
paddle.Tensor.fill_diagonal_tensor_(x, y, offset=0, dim1=0, dim2=1, name=None)
paddle.Tensor.flatten_(x, start_axis=0, stop_axis=-1, name=None)
paddle.Tensor.floor_(x, name=None)
paddle.Tensor.gradient(self)
paddle.Tensor.item(self, *args)
paddle.Tensor.lerp_(x, y, weight, name=None)
paddle.Tensor.ndimension(x)
paddle.Tensor.pin_memory(self)
paddle.Tensor.put_along_axis_(arr, indices, values, axis, reduce='assign')
paddle.Tensor.reciprocal_(x, name=None)
paddle.Tensor.register_hook(self, hook)
paddle.Tensor.remainder_(x, y, name=None)
paddle.Tensor.round_(x, name=None)
paddle.Tensor.rsqrt_(x, name=None)
paddle.Tensor.scale_(x, scale=1.0, bias=0.0, bias_after_scale=True, act=None, name=None)
paddle.Tensor.set_value(self, value)
paddle.Tensor.sqrt_(x, name=None)
paddle.Tensor.subtract_(x, y, name=None)
paddle.Tensor.to_dense(self)
paddle.Tensor.to_sparse_coo(self, sparse_dim)
paddle.Tensor.uniform_(x, min=-1.0, max=1.0, seed=0, name=None)
paddle.Tensor.value(self)
paddle.Tensor.values(self)
paddle.Tensor.zero_(x)
paddle.text.Conll05st(data_file=None, word_dict_file=None, verb_dict_file=None, target_dict_file=None, emb_file=None, download=True)
paddle.text.Imdb(data_file=None, mode='train', cutoff=150, download=True)
paddle.text.Imikolov(data_file=None, data_type='NGRAM', window_size=-1, mode='train', min_word_freq=50, download=True)
paddle.text.Movielens(data_file=None, mode='train', test_ratio=0.1, rand_seed=0, download=True)
paddle.text.UCIHousing(data_file=None, mode='train', download=True)
paddle.text.viterbi_decode(potentials, transition_params, lengths, include_bos_eos_tag=True, name=None)
paddle.text.ViterbiDecoder(transitions, include_bos_eos_tag=True, name=None)
paddle.text.WMT14(data_file=None, mode='train', dict_size=-1, download=True)
paddle.text.WMT16(data_file=None, mode='train', src_dict_size=-1, trg_dict_size=-1, lang='en', download=True)
paddle.utils.deprecated(update_to='', since='', reason='', level=0)
paddle.utils.require_version(min_version, max_version=None)
paddle.utils.run_check()
paddle.utils.try_import(module_name)
paddle.version.cuda()
paddle.version.cudnn()
paddle.version.show()
paddle.vision.get_image_backend()
paddle.vision.image_load(path, backend=None)
paddle.vision.set_image_backend(backend)